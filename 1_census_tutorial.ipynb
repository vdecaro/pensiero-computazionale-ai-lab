{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_census_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqNhHl/+jch6DkfT6Oe9qm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urZOIwgHXBLB"
      },
      "source": [
        "#Tutorial overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCp8VnyxVppJ"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2j320zLaAZf"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "In questa sezione creiamo una data pipeline per scaricare i dati, processarli, standardizzarli e riportarli in un formato che sia utilizzabile dalla nostra rete neurale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awP73EKYhW2l"
      },
      "source": [
        "Download URL e gestione dei path del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JfirVx2ZAh3"
      },
      "source": [
        "DATA_DIR = './sample_data/census_data'\n",
        "DATA_URL = 'https://storage.googleapis.com/cloud-samples-data/ai-platform/census/data'\n",
        "TRAINING_FILE = 'adult.data.csv'\n",
        "EVAL_FILE = 'adult.test.csv'\n",
        "TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
        "EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xm-S2k8ofm8"
      },
      "source": [
        "Informazioni sulle colonne del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU9XeVpjojow"
      },
      "source": [
        "_CSV_COLUMNS = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
        "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
        "    'income_bracket'\n",
        "]\n",
        "\n",
        "_LABEL_COLUMN = 'income_bracket'\n",
        "\n",
        "_CATEGORICAL_TYPES = {\n",
        "    'workclass': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc',\n",
        "        'Self-emp-not-inc', 'State-gov', 'Without-pay'\n",
        "    ]),\n",
        "    'marital_status': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
        "        'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'\n",
        "    ]),\n",
        "    'occupation': pd.api.types.CategoricalDtype([\n",
        "        'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial',\n",
        "        'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct',\n",
        "        'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv',\n",
        "        'Sales', 'Tech-support', 'Transport-moving'\n",
        "    ]),\n",
        "    'relationship': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried',\n",
        "        'Wife'\n",
        "    ]),\n",
        "    'race': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
        "    ]),\n",
        "    'native_country': pd.api.types.CategoricalDtype(categories=[\n",
        "        'Cambodia', 'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic',\n",
        "        'Ecuador', 'El-Salvador', 'England', 'France', 'Germany', 'Greece',\n",
        "        'Guatemala', 'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong',\n",
        "        'Hungary',\n",
        "        'India', 'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos',\n",
        "        'Mexico',\n",
        "        'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n",
        "        'Poland',\n",
        "        'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand',\n",
        "        'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'\n",
        "    ]),\n",
        "    'income_bracket': pd.api.types.CategoricalDtype(categories=[\n",
        "        '<=50K', '>50K'\n",
        "    ])\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZhPlEetcLWi"
      },
      "source": [
        "## Data Loading\n",
        "Creiamo la funzione per scaricare il dataset e riportarli in un formato utile per il preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7OQyfTUgFAs"
      },
      "source": [
        "def _download_and_clean_file(filename, url):\n",
        "    \"\"\"\n",
        "    Scarica i dati dall'URL e li modifica in modo da coincidere col formato CSV.\n",
        "    Args:\n",
        "      filename: filename dove salvare i dati\n",
        "      url: URL della risorsa da cui scaricare i dati\n",
        "    \"\"\"\n",
        "    temp_file, _ = urllib.request.urlretrieve(url)\n",
        "    with tf.io.gfile.GFile(temp_file, 'r') as temp_file_object:\n",
        "        with tf.io.gfile.GFile(filename, 'w') as file_object:\n",
        "            for line in temp_file_object:\n",
        "                line = line.strip()\n",
        "                line = line.replace(', ', ',')\n",
        "                if not line or ',' not in line:\n",
        "                    continue\n",
        "                if line[-1] == '.':\n",
        "                    line = line[:-1]\n",
        "                line += '\\n'\n",
        "                file_object.write(line)\n",
        "    tf.io.gfile.remove(temp_file)\n",
        "\n",
        "\n",
        "def download(data_dir):\n",
        "    \"\"\"Scarica il dataset se non √® gi√† presente.\n",
        "    Args:\n",
        "      data_dir: directory dalla quale avremo accesso al dataset\n",
        "    \"\"\"\n",
        "    tf.io.gfile.makedirs(data_dir)\n",
        "\n",
        "    training_file_path = os.path.join(data_dir, TRAINING_FILE)\n",
        "    if not tf.io.gfile.exists(training_file_path):\n",
        "        _download_and_clean_file(training_file_path, TRAINING_URL)\n",
        "\n",
        "    eval_file_path = os.path.join(data_dir, EVAL_FILE)\n",
        "    if not tf.io.gfile.exists(eval_file_path):\n",
        "        _download_and_clean_file(eval_file_path, EVAL_URL)\n",
        "\n",
        "    return training_file_path, eval_file_path"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7coANIeAGHBF"
      },
      "source": [
        "training_file_path, eval_file_path = download(DATA_DIR)\n",
        "\n",
        "# Se √® andato a buon fine, dovrebbe mostrare i files adult.data.csv and adult.test.csv\n",
        "!ls -l $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxa7XdwqGR41"
      },
      "source": [
        "Carichiamo i dati in un Pandas Dataframe e diamo una prima occhiata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFqg2F2dGWGu"
      },
      "source": [
        "train_df = pd.read_csv(training_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "eval_df = pd.read_csv(eval_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "\n",
        "# Here's what the data looks like before we preprocess the data.\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIFonuSecND7"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Il preprocessing √® una fase chiave di qualsiasi pipeline di Machine Learning: i dati devono sempre essere puliti, riscalati e resi fruibili per il modello di ML che vogliamo utilizzare. \n",
        "\n",
        "Ricordate il mantra di chiunque faccia analisi dati: garbage-in ‚û° garbage-out. üòÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYdvKBYPI2eV"
      },
      "source": [
        "### Cleaning\n",
        "\n",
        "Qualsiasi dataset deve passare sempre da una fase di cleaning in cui dobbiamo trattare eventuali valori mancanti, decidere se mantenere gli outliers e scegliere le features utili.\n",
        "\n",
        "In questo caso, possiamo limitarci tratteniamo esclusivamente le colonne utili. Cosa significa \"utili\"? E perch√©?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCF08Gv9gOnU"
      },
      "source": [
        "UNUSED_COLUMNS = ['fnlwgt', 'education', 'gender']\n",
        "\n",
        "def cleaning(dataframe):\n",
        "    \"\"\"\n",
        "    Rimuove le colonne superflue e codifica i valori categorici.\n",
        "    Args:\n",
        "      dataframe: Pandas dataframe with raw data\n",
        "    Returns:\n",
        "      Dataframe with preprocessed data\n",
        "    \"\"\"\n",
        "    return dataframe.drop(columns=UNUSED_COLUMNS)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XnJKn-VKi2x"
      },
      "source": [
        "train_x = cleaning(train_x)\n",
        "eval_x = cleaning(eval_x)\n",
        "train_x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzFO1TYo9ddw"
      },
      "source": [
        "### Codifica dei valori categorici\n",
        "\n",
        "I valori categorici di solito sono definiti come insiemi discreti dove gli elementi definiscono una certa categoria (in senso lato). \\\\\n",
        "La prassi √® assegnare a ciascun elemento dell'insieme un codice che lo identifichi univocamente al suo interno.\n",
        "\n",
        "Esempio: `frutta = {mela, pera, banana}` ‚û° `frutta = {0, 1, 2}` con `mela=1`, `pera=2`, `banana= 3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry9l4Gj39CFE"
      },
      "source": [
        "def categorical_to_numeric(dataframe):\n",
        "    # Convertiamo i valori numerici a float32.\n",
        "    numeric_columns = dataframe.select_dtypes(['int64']).columns\n",
        "    dataframe[numeric_columns] = dataframe[numeric_columns].astype('float32')\n",
        "\n",
        "    # Conversione dei valori categorici a numerici.\n",
        "    cat_columns = dataframe.select_dtypes(['object']).columns\n",
        "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.astype(_CATEGORICAL_TYPES[x.name]))\n",
        "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.cat.codes)\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVQE4ITdMUtc"
      },
      "source": [
        "train_x = categorical_to_numeric(train_x)\n",
        "eval_x = categorical_to_numeric(eval_x)\n",
        "train_x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBODxNVNgeAW"
      },
      "source": [
        "### Rescaling\n",
        "\n",
        "Due tra le tipologie di rescaling pi√π utilizzate sono le seguenti:\n",
        "* Standardizzazione con z-score: `(x - x_mean)/std` ;\n",
        "* Min-max scaling: `(x_max - x) / (x_max - x_min)` . \n",
        "\n",
        "Il rescaling √® una fase fondamentale di qualsiasi data pipeline. Vediamo perch√© nel caso delle reti neurali."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFVEgt9jg-c1"
      },
      "source": [
        "def standardize(dataframe):\n",
        "    \"\"\"\n",
        "    Riscala le colonne numeriche tramite standardizzazione con z-score.\n",
        "    Args:\n",
        "      dataframe: Pandas dataframe\n",
        "    Returns:\n",
        "      Il dataframe in input con le colonne numeriche riscalate.\n",
        "    \"\"\"\n",
        "    dtypes = list(zip(dataframe.dtypes.index, map(str, dataframe.dtypes)))\n",
        "    # Normalize numeric columns.\n",
        "    for column, dtype in dtypes:\n",
        "        if dtype == 'float32':\n",
        "            dataframe[column] -= dataframe[column].mean()\n",
        "            dataframe[column] /= dataframe[column].std()\n",
        "    return dataframe"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dnWB44AMxqX"
      },
      "source": [
        "Uniamo `train_x` ed `eval_x` per fare la normalizzazione rispetto alla media e alla deviazione standard di tutti dati. Dopodich√© li separiamo nuovamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iffqChk3Ms9P"
      },
      "source": [
        "all_x = pd.concat([train_x, eval_x], keys=['train', 'eval'])\n",
        "all_x = standardize(all_x)\n",
        "train_x, eval_x = all_x.xs('train'), all_x.xs('eval')\n",
        "train_x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbzgiviRrnYr",
        "outputId": "1e0f9120-6c87-4ca8-db3c-3899d2d3f487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# Download Census dataset: Training and eval csv files.\n",
        "training_file_path, eval_file_path = download(DATA_DIR)\n",
        "\n",
        "train_df = pd.read_csv(training_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "eval_df = pd.read_csv(eval_file_path, names=_CSV_COLUMNS, na_values='?')\n",
        "train_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  ... hours_per_week  native_country income_bracket\n",
              "0   39         State-gov   77516  ...             40   United-States          <=50K\n",
              "1   50  Self-emp-not-inc   83311  ...             13   United-States          <=50K\n",
              "2   38           Private  215646  ...             40   United-States          <=50K\n",
              "3   53           Private  234721  ...             40   United-States          <=50K\n",
              "4   28           Private  338409  ...             40            Cuba          <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NXqKVq3NCAn"
      },
      "source": [
        "Dividiamo dati di training e di validazione dal label che vogliamo predire. Il metodo `pop` copia la colonna del label e la rimuove dal dataframe.\n",
        "\n",
        "Dopodich√©, facciamo reshaping dei vettori dei label per renderli in un formato `[1 x num_samples]`, che utilizzeremo successivamente in `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8p6iVLojTnt"
      },
      "source": [
        "train_x, train_y = train_df, train_df.pop(_LABEL_COLUMN)\n",
        "eval_x, eval_y = eval_df, eval_df.pop(_LABEL_COLUMN)\n",
        "\n",
        "train_y = np.asarray(train_y).astype('float32').reshape((-1, 1))\n",
        "eval_y = np.asarray(eval_y).astype('float32').reshape((-1, 1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA8pTiLuraPS",
        "outputId": "028e146e-c8e9-45cc-bd19-9654bc5a3cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "train_x.head(), train_y, eval_x.head(), eval_y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.025997</td>\n",
              "      <td>6</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.146933</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.828278</td>\n",
              "      <td>5</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-2.212964</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.046938</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.419265</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.047082</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.197188</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.776285</td>\n",
              "      <td>3</td>\n",
              "      <td>1.136580</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.144792</td>\n",
              "      <td>-0.217132</td>\n",
              "      <td>-0.034039</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  workclass  ...  hours_per_week  native_country\n",
              "0  0.025997          6  ...       -0.034039              38\n",
              "1  0.828278          5  ...       -2.212964              38\n",
              "2 -0.046938          3  ...       -0.034039              38\n",
              "3  1.047082          3  ...       -0.034039              38\n",
              "4 -0.776285          3  ...       -0.034039               4\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZFSL1GtNSNM"
      },
      "source": [
        "Bene, il nostro dataset adesso √® in un formato fruibile dalla nostra rete neurale. Passiamo alla parte divertente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-q7EC93bSOM"
      },
      "source": [
        "# Keras Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N96rtGusATdQ"
      },
      "source": [
        "def input_fn(features, labels, shuffle, num_epochs, batch_size):\n",
        "    \"\"\"Generates an input function to be used for model training.\n",
        "    Args:\n",
        "      features: numpy array of features used for training or inference\n",
        "      labels: numpy array of labels for each example\n",
        "      shuffle: boolean for whether to shuffle the data or not (set True for\n",
        "        training, False for evaluation)\n",
        "      num_epochs: number of epochs to provide the data for\n",
        "      batch_size: batch size for training\n",
        "    Returns:\n",
        "      A tf.data.Dataset that can provide data to the Keras model for training or\n",
        "        evaluation\n",
        "    \"\"\"\n",
        "    if labels is None:\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "\n",
        "    # We call repeat after shuffling, rather than before, to prevent separate\n",
        "    # epochs from blending together.\n",
        "    dataset = dataset.repeat(num_epochs)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def create_keras_model(input_dim, learning_rate):\n",
        "    \"\"\"Creates Keras Model for Binary Classification.\n",
        "    The single output node + Sigmoid activation makes this a Logistic\n",
        "    Regression.\n",
        "    Args:\n",
        "      input_dim: How many features the input has\n",
        "      learning_rate: Learning rate for training\n",
        "    Returns:\n",
        "      The compiled Keras model (still needs to be trained)\n",
        "    \"\"\"\n",
        "    Dense = tf.keras.layers.Dense\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            Dense(100, activation=tf.nn.relu, kernel_initializer='uniform',\n",
        "                  input_shape=(input_dim,)),\n",
        "            Dense(75, activation=tf.nn.relu),\n",
        "            Dense(50, activation=tf.nn.relu),\n",
        "            Dense(25, activation=tf.nn.relu),\n",
        "            Dense(1, activation=tf.nn.sigmoid)\n",
        "        ])\n",
        "\n",
        "    # Custom Optimizer:\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate)\n",
        "\n",
        "    # Compile Keras model\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31oqOgJbP6l"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "from . import model\n",
        "from . import util\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    \"\"\"Argument parser.\n",
        "    Returns:\n",
        "      Dictionary of arguments.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--job-dir',\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help='local or GCS location for writing checkpoints and exporting '\n",
        "             'models')\n",
        "    parser.add_argument(\n",
        "        '--num-epochs',\n",
        "        type=int,\n",
        "        default=20,\n",
        "        help='number of times to go through the data, default=20')\n",
        "    parser.add_argument(\n",
        "        '--batch-size',\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help='number of records to read during each training step, default=128')\n",
        "    parser.add_argument(\n",
        "        '--learning-rate',\n",
        "        default=.01,\n",
        "        type=float,\n",
        "        help='learning rate for gradient descent, default=.01')\n",
        "    parser.add_argument(\n",
        "        '--verbosity',\n",
        "        choices=['DEBUG', 'ERROR', 'FATAL', 'INFO', 'WARN'],\n",
        "        default='INFO')\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def train_and_evaluate(args):\n",
        "    \"\"\"Trains and evaluates the Keras model.\n",
        "    Uses the Keras model defined in model.py and trains on data loaded and\n",
        "    preprocessed in util.py. Saves the trained model in TensorFlow SavedModel\n",
        "    format to the path defined in part by the --job-dir argument.\n",
        "    Args:\n",
        "      args: dictionary of arguments - see get_args() for details\n",
        "    \"\"\"\n",
        "\n",
        "    train_x, train_y, eval_x, eval_y = util.load_data()\n",
        "\n",
        "    # dimensions\n",
        "    num_train_examples, input_dim = train_x.shape\n",
        "    num_eval_examples = eval_x.shape[0]\n",
        "\n",
        "    # Create the Keras Model\n",
        "    keras_model = model.create_keras_model(\n",
        "        input_dim=input_dim, learning_rate=args.learning_rate)\n",
        "\n",
        "    # Pass a numpy array by passing DataFrame.values\n",
        "    training_dataset = model.input_fn(\n",
        "        features=train_x.values,\n",
        "        labels=train_y,\n",
        "        shuffle=True,\n",
        "        num_epochs=args.num_epochs,\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Pass a numpy array by passing DataFrame.values\n",
        "    validation_dataset = model.input_fn(\n",
        "        features=eval_x.values,\n",
        "        labels=eval_y,\n",
        "        shuffle=False,\n",
        "        num_epochs=args.num_epochs,\n",
        "        batch_size=num_eval_examples)\n",
        "\n",
        "    # Setup Learning Rate decay.\n",
        "    lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
        "        lambda epoch: args.learning_rate + 0.02 * (0.5 ** (1 + epoch)),\n",
        "        verbose=True)\n",
        "\n",
        "    # Setup TensorBoard callback.\n",
        "    tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
        "        os.path.join(args.job_dir, 'keras_tensorboard'),\n",
        "        histogram_freq=1)\n",
        "\n",
        "    # Train model\n",
        "    keras_model.fit(\n",
        "        training_dataset,\n",
        "        steps_per_epoch=int(num_train_examples / args.batch_size),\n",
        "        epochs=args.num_epochs,\n",
        "        validation_data=validation_dataset,\n",
        "        validation_steps=1,\n",
        "        verbose=1,\n",
        "        callbacks=[lr_decay_cb, tensorboard_cb])\n",
        "\n",
        "    export_path = os.path.join(args.job_dir, 'keras_export')\n",
        "    tf.keras.experimental.export_saved_model(keras_model, export_path)\n",
        "    print('Model exported to: {}'.format(export_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = get_args()\n",
        "    tf.compat.v1.logging.set_verbosity(args.verbosity)\n",
        "    train_and_evaluate(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u37CQGQQbwTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}