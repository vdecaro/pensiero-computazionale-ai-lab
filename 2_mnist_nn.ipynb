{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow/datasets",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSV_OlCFKOD"
      },
      "source": [
        "# Allenare una rete neurale su MNIST tramite Keras\n",
        "\n",
        "Questa volta tocca a voi. Il task è quello di implementare una rete neurale per un noto task di classificazione della computer vision.\n",
        "\n",
        "## Caso d'uso\n",
        "\n",
        "Il caso d'uso di questo task deriva dal dataset **MNIST**, uno dei benchmark ad oggi più diffusi nella computer vision. In questo dataset sono presenti 70000 immagini (60000 per il training e 10000 per la validazione) in grayscale di dimensione `26x26` rappresentanti cifre da 0 a 9. \n",
        "\n",
        "L'**obiettivo** è quello di costruire e allenare una rete neurale che, data un'immagine, discrimini correttamente quale delle 10 cifre è rappresentata in essa.\n",
        "\n",
        "## Modalità\n",
        "Nel notebook troverete parti già completate e parti dove è presente il tag ***@TODO*** seguito da una breve descrizione. Il compito sarà quello di completare correttamente le parti dove è presente il tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjI6VgOBf0v0"
      },
      "source": [
        "# Dataset\n",
        "Anche qui, cominciamo con la definizione di alcune costanti "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RldbrLh31k4k"
      },
      "source": [
        "IMG_SHAPE = (28, 28)\n",
        "MAX_PIXEL_VALUE = 255\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3aH3vP_XLI8"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "Considerando la popolarità di questo dataset, Keras fornisce già una funzione per importarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUMhCXhFXdHQ"
      },
      "source": [
        "(x_train, y_train), (x_eval, y_eval) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5-NbHh0sjXH"
      },
      "source": [
        "figsize(20, 5)\n",
        "for i in range(16):\n",
        "  subplot(2, 8, i+1)\n",
        "  imshow(x_train[i], cmap=\"binary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgwCFAcWXQTx"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVITeGTr6hzP"
      },
      "source": [
        "### Rescaling\n",
        "\n",
        "***@TODO***: riscalare sia `x_train` che `x_eval` in modo che assumano solo valori tra 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haykx2K9XgiI"
      },
      "source": [
        "def normalize(dataset):\n",
        "  pass\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi8OFkrl7Cb7"
      },
      "source": [
        "x_train, x_eval = normalize(x_train), normalize(x_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbsMy4X1XVFv"
      },
      "source": [
        "# Training pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui60T0XE8cYd"
      },
      "source": [
        "##`input_fn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toovEVDx85Tk"
      },
      "source": [
        "def input_fn(features, labels, shuffle, num_epochs, batch_size):\n",
        "    \"\"\"Genera una funzione di input per il modello Keras.\n",
        "    Args:\n",
        "      features: numpy array delle features utilizzate per training o inferenza\n",
        "      labels: numpy array delle etichette di ciascun esempio\n",
        "      shuffle: booleano che determina se bisogna fare uno shuffle dei dati (True \n",
        "        per il training, False per la validazione)\n",
        "      num_epochs: numero di epoche di training\n",
        "      batch_size: batch size in fase di training\n",
        "    Returns:\n",
        "      tf.data.Dataset che può fornite i dati al Keras model per training o \n",
        "        inferenza\n",
        "    \"\"\"\n",
        "    if labels is None:\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(features))\n",
        "\n",
        "    # Utilizziamo la repeat dopo lo shuffle per evitare che epoche separate si \n",
        "    # mischino.\n",
        "    dataset = dataset.repeat(num_epochs)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aobAqj5Q86u1"
      },
      "source": [
        "***@TODO***: creare un training dataset in modo che iteri per 10 epoche, con batch di 128 elementi e faccia shuffle.\n",
        "\n",
        "***@TODO***: creare un validation dataset in modo che iteri per 10 epoche, con batch pari alla dimensione del validation set e non faccia shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0KjuDf7XiqY"
      },
      "source": [
        "training_dataset = None\n",
        "\n",
        "validation_dataset = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTFoji3INMEM"
      },
      "source": [
        "## `create_keras_model`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAik7sEz-FGh"
      },
      "source": [
        "***@TODO***: creare un Keras sequential model dove\n",
        "\n",
        "* Il primo layer fa il [flattening](https://keras.io/api/layers/reshaping_layers/flatten/) dell'input per riportarlo in forma vettoriale (la rete neurale non può prendere matrici in input). Si noti che il layer di flattening prende in input la `shape` dei dati;\n",
        "* Il secondo layer è un layer da 128 unità e ha come funzione di attivazione la `relu`;\n",
        "* L'ultimo layer ha un numero di unità pari al numero di classi, e non ha funzione di attivazione (layer lineare)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I7aNFzA95sx"
      },
      "source": [
        "def create_keras_model(input_shape):\n",
        "    \"\"\"Crea un modello Keras per classificazione binaria.\n",
        "    Args:\n",
        "      input_shape: la tupla che rappresenta la dimensione dell'immagine\n",
        "    Returns:\n",
        "      Keras model\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axHG4ozkAwyw"
      },
      "source": [
        "model = create_keras_model(#TODO: assegnare la image shape corretta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWz4oEG_kYT"
      },
      "source": [
        "##```link_optimizer```\n",
        "***TODO***: compilare il modello in modo che\n",
        "* L'ottimizzatore sia [adam](https://keras.io/api/optimizers/adam/) con learning rate uguale a 0.001;\n",
        "* La funzione di loss sia la [Sparse Categorical Cross-Entropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_crossentropy) con parametro `from_logits=True`;\n",
        "* L'unica metrica utilizzata sia la [Sparse Categorical Accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsiJcZrtA6Ur"
      },
      "source": [
        "def link_optimizer(model, learning_rate):\n",
        "    '''\n",
        "    Crea un ottimizzatore e compila il modello.\n",
        "    Args:\n",
        "      model: il Keras model a cui dobbiamo linkare l'ottimizzatore\n",
        "      learning_rate: il learning rate dell'ottimizzatore\n",
        "    Returns:\n",
        "      il Keras model compilato\n",
        "    '''\n",
        "    pass\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mUARoeIBP3c"
      },
      "source": [
        "model = link_optimizer(model, #TODO: assegnare il learning rate corretto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kySMgNZBXkX"
      },
      "source": [
        "##`fit`\n",
        "\n",
        "***@TODO***: allenare il modello tramite il metodo `fit`\n",
        "1. per 10 epoche;\n",
        "2. `steps_per_epoch` definito correttamente (ricordare che Keras conta in batch, quindi un'epoca deve essere costituita da tutti i batch che possiamo creare dal dataset); \n",
        "3. Uno step di validazione come abbiamo visto nel tutorial precedente\n",
        "4. `verbose=1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWqxdmS1NLKA"
      },
      "source": [
        "history = model.fit(\n",
        "    #TODO: assegnare i parametri corretti\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j34Xd-60C249"
      },
      "source": [
        "# Visualizzazione dei risultati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQx8gbsFC8DQ"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Ic8Hq2C85K"
      },
      "source": [
        "plt.title('Keras model loss')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJgNOHxbC_c3"
      },
      "source": [
        "plt.title('Keras model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.legend(['training', 'validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9HCklzxEzQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}